{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T0RioP__jY7X"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfyGmJGHWZg3","outputId":"8bb0e36f-c60e-4ebd-b290-38c39cf43b6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras_self_attention in /usr/local/lib/python3.7/dist-packages (0.50.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (2.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.19.5)\n"]}],"source":["!pip install keras_self_attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQ8SsPUGLEVd"},"outputs":[],"source":["import pickle\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras_self_attention import SeqSelfAttention\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from keras import backend as K\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwvPr6LsN2jK"},"outputs":[],"source":["features = 1280\n","# 2048 for ResNet\n","# 1024 for DenseNet\n","# 1280 for MobileNet\n","output_file = '/content/drive/MyDrive/MobileNetV2_Results_.p'\n","\n","\n","with open ('/content/drive/MyDrive//saveX_MobileNet.p', 'rb') as fp:\n","  X = pickle.load(fp)\n","    \n","with open ('/content/drive/MyDrive/saveY_MobileNet.p', 'rb') as fp:\n","  Y = pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie5kRHYSOAld"},"outputs":[],"source":["def pad_into_array(list, total_length):\n","  T = []\n","    \n","  for i in range(len(list)):\n","    pad = total_length - X[i].shape[0]\n","    if pad <= 0:\n","      T.append(list[i][:total_length, :])\n","    else:\n","      T.append(np.pad(list[i], [(0, pad), (0, 0)]))\n","  \n","  return np.array(T)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKf5oKc5WCDa"},"outputs":[],"source":["def print_plots(history, neurons, depth, model_type):\n","\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'valid'], loc='upper left')\n","  plt.savefig('/content/drive/MyDrive/Type{}_Depth{}_Neurons{}_Acc.png'.format(model_type, depth, neurons))\n","  plt.clf()\n","\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('model loss')\n","  plt.ylabel('loss')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'valid'], loc='upper left')\n","  plt.savefig('/content/drive/MyDrive/Type{}_Depth{}_Neurons{}_Loss.png'.format(model_type, depth, neurons))\n","  plt.clf()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iZteZ18OC6J","outputId":"665cd916-6168-453c-bb5a-42740a29d363"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'>\n","(1600, 30, 1280)\n","<class 'numpy.ndarray'>\n","(1600, 11)\n"]}],"source":["max_length = 30\n","\n","X = pad_into_array(X, max_length)\n","\n","print(type(X))\n","print(X.shape)\n","print(type(Y))\n","print(Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLtgO4P3OGC2","outputId":"68de0c09-f87f-4cf3-aa37-62ca09e535fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1280, 30, 1280)\n","(1280, 11)\n","(320, 30, 1280)\n","(320, 11)\n"]}],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=22)\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","print(X_test.shape)\n","print(Y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"829Zf_huXkov","outputId":"aaeda377-189c-43f2-b89f-85573fba628d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [Type, Depth, Neurons, Accuracy, Loss]\n","Index: []\n"]}],"source":["total_neurons = [32, 64, 128, 256]\n","output_classes = 11\n","\n","results = pd.DataFrame(columns = ['Type', 'Depth', 'Neurons', 'Accuracy', 'Loss'])\n","print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"BPfRIRG6O0Nt","outputId":"4cd5dab3-4c69-4fdb-b2c2-3623b5af64c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Doing Type 1, Depth 1, Neuron 32\n","Doing Type 1, Depth 2, Neuron 32\n","Doing Type 1, Depth 3, Neuron 32\n","Doing Type 1, Depth 1, Neuron 64\n","Doing Type 1, Depth 2, Neuron 64\n","Doing Type 1, Depth 3, Neuron 64\n","Doing Type 1, Depth 1, Neuron 128\n","Doing Type 1, Depth 2, Neuron 128\n","Doing Type 1, Depth 3, Neuron 128\n","Doing Type 1, Depth 1, Neuron 256\n","Doing Type 1, Depth 2, Neuron 256\n","Doing Type 1, Depth 3, Neuron 256\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for neurons in total_neurons:\n","    \n","  print('Doing Type 1, Depth 1, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.LSTM(neurons))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '1(LSTM)', 'Depth' : 1, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 1, 1)\n","    \n","  K.clear_session()\n","  \n","  print('Doing Type 1, Depth 2, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.LSTM(neurons, return_sequences=True))\n","  model.add(layers.LSTM(neurons))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '1(LSTM)', 'Depth' : 2, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 2, 1)\n","    \n","  K.clear_session()\n","  \n","  print('Doing Type 1, Depth 3, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.LSTM(neurons, return_sequences=True))\n","  model.add(layers.LSTM(neurons, return_sequences=True))\n","  model.add(layers.LSTM(neurons))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '1(LSTM)', 'Depth' : 3, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 3, 1)\n","    \n","  K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"728NW8w3Xywx","outputId":"4b1b8d6e-8372-41fc-9d87-60562a4ddb90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Doing Type 2, Depth 1, Neuron 32\n","Doing Type 2, Depth 2, Neuron 32\n","Doing Type 2, Depth 3, Neuron 32\n","Doing Type 2, Depth 1, Neuron 64\n","Doing Type 2, Depth 2, Neuron 64\n","Doing Type 2, Depth 3, Neuron 64\n","Doing Type 2, Depth 1, Neuron 128\n","Doing Type 2, Depth 2, Neuron 128\n","Doing Type 2, Depth 3, Neuron 128\n","Doing Type 2, Depth 1, Neuron 256\n","Doing Type 2, Depth 2, Neuron 256\n","Doing Type 2, Depth 3, Neuron 256\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for neurons in total_neurons:\n","    \n","  print('Doing Type 2, Depth 1, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons)))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '2(BiLSTM)', 'Depth' : 1, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 1, 2)\n","    \n","  K.clear_session()\n","    \n","  print('Doing Type 2, Depth 2, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons)))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '2(BiLSTM)', 'Depth' : 2, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 2, 2)\n","    \n","  K.clear_session()\n","  \n","  print('Doing Type 2, Depth 3, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons)))\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '2(BiLSTM)', 'Depth' : 3, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 3, 2)\n","    \n","  K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"b7XX_AMXXym4","outputId":"949927b6-fa5d-410e-9cf2-fcdb7f86bb31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Doing Type 3, Depth 1, Neuron 32\n","Doing Type 3, Depth 2, Neuron 32\n","Doing Type 3, Depth 3, Neuron 32\n","Doing Type 3, Depth 1, Neuron 64\n","Doing Type 3, Depth 2, Neuron 64\n","Doing Type 3, Depth 3, Neuron 64\n","Doing Type 3, Depth 1, Neuron 128\n","Doing Type 3, Depth 2, Neuron 128\n","Doing Type 3, Depth 3, Neuron 128\n","Doing Type 3, Depth 1, Neuron 256\n","Doing Type 3, Depth 2, Neuron 256\n","Doing Type 3, Depth 3, Neuron 256\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for neurons in total_neurons:\n","    \n","  print('Doing Type 3, Depth 1, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(SeqSelfAttention(attention_activation='sigmoid'))\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '3(AttBiLSTM)', 'Depth' : 1, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 1, 3)\n","    \n","  K.clear_session()\n","    \n","  print('Doing Type 3, Depth 2, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(SeqSelfAttention(attention_activation='sigmoid'))\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '3(AttBiLSTM)', 'Depth' : 2, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 2, 3)\n","    \n","  K.clear_session()\n","  \n","  print('Doing Type 3, Depth 3, Neuron {}'.format(neurons))\n","  model = keras.Sequential()\n","  model.add(keras.Input(shape=(max_length, features)))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(layers.Bidirectional(layers.LSTM(neurons, return_sequences=True)))\n","  model.add(SeqSelfAttention(attention_activation='sigmoid'))\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(output_classes, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","  history = model.fit(X_train, Y_train, batch_size=30, epochs=20, validation_split=0.25, verbose=0)\n","  \n","  test_scores = model.evaluate(X_test, Y_test, verbose=0)\n","  results = results.append({'Type' : '3(AttBiLSTM)', 'Depth' : 3, 'Neurons' : neurons, 'Accuracy' : test_scores[1], 'Loss' : test_scores[0]}, ignore_index = True)\n","  \n","  print_plots(history, neurons, 3, 3)\n","    \n","  K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BqvfpVKPO2S"},"outputs":[],"source":["with open(output_file, 'wb') as fp:\n","    pickle.dump(results, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82mWQJyMxo_2"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LSTM_Final.ipynb","provenance":[]},"kernelspec":{"display_name":"ai","language":"python","name":"cv"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}